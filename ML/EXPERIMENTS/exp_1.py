# -*- coding: utf-8 -*-
"""EXP-1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TOou0VjSftncqtZKPCIxfDiWPVKP0_Bc
"""

from google.colab import drive
drive.mount('/content/gdrive')

"""### 1. without sklearn"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

X = [i for i in range(2,11)]
Y = [1,3,6,9,11,13,15,17,20]

df = pd.DataFrame({'X':X,'Y':Y})

X = df['X'].values.reshape(-1,1)
Y = df['Y'].values.reshape(-1,1)

learning_rate=0.01
no_of_itr=100
y_pred_arr = []

m,n = X.shape
w = np.zeros((n,1))
b = 0

def predict(X):
    return X.dot(w) + b

def update_wt():
    global w
    global b
    y_pred = predict(X)
    y_pred_arr.append(y_pred)

    # calculating gradients
    dw = -(X.T).dot(Y - y_pred)/m

    db = -np.sum(Y - y_pred)/m

    # updating weights
    w = w - learning_rate * dw
    b = b - learning_rate * db

for i in range(no_of_itr):
  update_wt()

print(w)
print(b)
MSE = np.square(np.subtract(Y,y_pred_arr)).mean()
print(MSE)

"""### 1.2 with *sklearn*"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

X = df['X'].values.reshape(-1,1)
Y = df['Y'].values.reshape(-1,1)

model = LinearRegression()
model.fit(X,Y)
print(model.score)

"""### 2.1 with dataset with lib"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

df = pd.read_csv('/content/gdrive/MyDrive/DMW/datasets/StudentsPerformance.csv')
df.head()

df['final_score'] = df.apply(lambda x: (x['math score'] + x['reading score'] + x['writing score'])/3, axis=1)

df2 = df
df2 = df2.drop(['math score','reading score','writing score'],axis=1)

df2.head()

df2 = pd.get_dummies(df2, columns=['gender','lunch','parental level of education','race/ethnicity','test preparation course'])

df2.head()

# multi-variate
y = df2['final_score']
x = df2.drop(['final_score'],axis=1)

xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.25,random_state=10)

model = LinearRegression()
model.fit(xtrain,ytrain)
score = model.score(xtest,ytest)
print(score)
ypred = model.predict(xtest)

"""### 2.2 with formula"""

X = df['X'].values.reshape(-1,1)
Y = df['Y'].values.reshape(-1,1)

learning_rate=0.01
no_of_itr=100
y_pred_arr = []

m,n = X.shape
w = np.zeros((n,1))
b = 0

def predict(X):
    return X.dot(w) + b

def update_wt():
    global w
    global b
    y_pred = predict(X)
    y_pred_arr.append(y_pred)

    # calculating gradients
    dw = -(X.T).dot(Y - y_pred)/m

    db = -np.sum(Y - y_pred)/m

    # updating weights
    w = w - learning_rate * dw
    b = b - learning_rate * db

for i in range(no_of_itr):
  update_wt()

print(w)
print(b)
MSE = np.square(np.subtract(Y,y_pred_arr)).mean()
print(MSE)

"""### 3.1 with lib"""

df = pd.read_csv('/content/gdrive/MyDrive/BDI/salary_data.csv')
df.head()

X = df['YearsExperience'].values.reshape(-1,1)
Y = df['Salary'].values.reshape(-1,1)

learning_rate=0.01
no_of_itr=100
y_pred_arr = []

m,n = X.shape
w = np.zeros((n,1))
b = 0

def predict(X):
    return X.dot(w) + b

def update_wt():
    global w
    global b
    y_pred = predict(X)
    y_pred_arr.append(y_pred)

    # calculating gradients
    dw = -(X.T).dot(Y - y_pred)/m

    db = -np.sum(Y - y_pred)/m

    # updating weights
    w = w - learning_rate * dw
    b = b - learning_rate * db

for i in range(no_of_itr):
  update_wt()

print(w)
print(b)
MSE = np.square(np.subtract(Y,y_pred_arr)).mean()
print(MSE)

"""# 3.2"""

model = LinearRegression()
model.fit(X,Y)
ypred = model.predict([[4]])
print(ypred)

